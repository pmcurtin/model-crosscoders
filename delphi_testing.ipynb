{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-22 22:09:38 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/oscar/scratch/pcurtin1\"\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForCausalLM\n",
    "from transformer_lens import HookedTransformer\n",
    "from typing import Callable\n",
    "import delphi\n",
    "import torch\n",
    "from models import CrossCoder\n",
    "import torch.nn.functional as F\n",
    "from delphi.config import CacheConfig, ConstructorConfig, RunConfig, SamplerConfig\n",
    "from delphi.utils import assert_type\n",
    "from pathlib import Path\n",
    "from delphi.__main__ import (\n",
    "    non_redundant_hookpoints,\n",
    "    create_neighbours,\n",
    "    process_cache,\n",
    "    populate_cache,\n",
    "    log_results,\n",
    ")\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "from delphi.log.result_analysis import get_metrics, load_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/some_model/version_1\"\n",
    "name = \"9\"\n",
    "layer=18\n",
    "\n",
    "\n",
    "def override_load_hooks_sparse_coders(model: AutoModel, cfg: RunConfig, compile: bool = False) -> tuple[dict[str, Callable], bool]:\n",
    "\n",
    "    model_a_str = \"Qwen/Qwen2.5-0.5B\"\n",
    "    model_b_str = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "    tokenizer_a = AutoTokenizer.from_pretrained(model_a_str)\n",
    "    tokenizer_b = AutoTokenizer.from_pretrained(model_b_str)\n",
    "\n",
    "    modelA = HookedTransformer.from_pretrained(\n",
    "        model_a_str, tokenizer=tokenizer_a, dtype=\"bfloat16\"\n",
    "    )\n",
    "    modelB = HookedTransformer.from_pretrained(\n",
    "        model_b_str, tokenizer=tokenizer_b, dtype=\"bfloat16\"\n",
    "    )\n",
    "\n",
    "    coder = CrossCoder.load(\n",
    "        name, modelA=modelA, modelB=modelB, path=model_path\n",
    "    )\n",
    "\n",
    "    del modelA, modelB\n",
    "\n",
    "    W_enc = coder.encoder.data\n",
    "    W_enc = W_enc.reshape(2, -1, W_enc.shape[1]).to(\"cuda\")\n",
    "    b_enc = coder.encoder_bias.data.to(\"cuda\")\n",
    "\n",
    "    def encode(x): \n",
    "\n",
    "        return F.relu(coder.topk_constraint(\n",
    "            x @ W_enc[0] + b_enc\n",
    "        ))\n",
    "\n",
    "    transcoder = False\n",
    "\n",
    "    assert len(cfg.hookpoints) == 1, \"only support one hook location\"\n",
    "\n",
    "    d = {\n",
    "        cfg.hookpoints[0]: encode\n",
    "    }\n",
    "\n",
    "    return d, transcoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "def load_artifacts(run_cfg: RunConfig):\n",
    "    if run_cfg.load_in_8bit:\n",
    "        dtype = torch.float16\n",
    "    elif torch.cuda.is_bf16_supported():\n",
    "        dtype = torch.bfloat16\n",
    "    else:\n",
    "        dtype = \"auto\"\n",
    "\n",
    "    model = AutoModel.from_pretrained(\n",
    "        run_cfg.model,\n",
    "        device_map={\"\": \"cuda\"},\n",
    "        quantization_config=(\n",
    "            BitsAndBytesConfig(load_in_8bit=run_cfg.load_in_8bit)\n",
    "            if run_cfg.load_in_8bit\n",
    "            else None\n",
    "        ),\n",
    "        torch_dtype=dtype,\n",
    "        token=run_cfg.hf_token,\n",
    "    )\n",
    "\n",
    "    hookpoint_to_sparse_encode, transcode = override_load_hooks_sparse_coders(\n",
    "        model,\n",
    "        run_cfg,\n",
    "        compile=True,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        list(hookpoint_to_sparse_encode.keys()),\n",
    "        hookpoint_to_sparse_encode,\n",
    "        model,\n",
    "        transcode,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run(\n",
    "    run_cfg: RunConfig,\n",
    "):\n",
    "    base_path = Path.cwd() / \"results\"\n",
    "    if run_cfg.name:\n",
    "        base_path = base_path / run_cfg.name\n",
    "\n",
    "    base_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    run_cfg.save_json(base_path / \"run_config.json\", indent=4)\n",
    "\n",
    "    latents_path = base_path / \"latents\"\n",
    "    explanations_path = base_path / \"explanations\"\n",
    "    scores_path = base_path / \"scores\"\n",
    "    neighbours_path = base_path / \"neighbours\"\n",
    "    visualize_path = base_path / \"visualize\"\n",
    "\n",
    "    latent_range = torch.arange(run_cfg.max_latents) if run_cfg.max_latents else None\n",
    "\n",
    "    hookpoints, hookpoint_to_sparse_encode, model, transcode = load_artifacts(run_cfg)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(run_cfg.model, token=run_cfg.hf_token)\n",
    "\n",
    "    nrh = assert_type(\n",
    "        dict,\n",
    "        non_redundant_hookpoints(\n",
    "            hookpoint_to_sparse_encode, latents_path, \"cache\" in run_cfg.overwrite\n",
    "        ),\n",
    "    )\n",
    "    if nrh:\n",
    "        populate_cache(\n",
    "            run_cfg,\n",
    "            model,\n",
    "            nrh,\n",
    "            latents_path,\n",
    "            tokenizer,\n",
    "            transcode,\n",
    "        )\n",
    "\n",
    "    del model, hookpoint_to_sparse_encode\n",
    "    if run_cfg.constructor_cfg.non_activating_source == \"neighbours\":\n",
    "        nrh = assert_type(\n",
    "            list,\n",
    "            non_redundant_hookpoints(\n",
    "                hookpoints, neighbours_path, \"neighbours\" in run_cfg.overwrite\n",
    "            ),\n",
    "        )\n",
    "        if nrh:\n",
    "            create_neighbours(\n",
    "                run_cfg,\n",
    "                latents_path,\n",
    "                neighbours_path,\n",
    "                nrh,\n",
    "            )\n",
    "    else:\n",
    "        print(\"Skipping neighbour creation\")\n",
    "\n",
    "    nrh = assert_type(\n",
    "        list,\n",
    "        non_redundant_hookpoints(\n",
    "            hookpoints, scores_path, \"scores\" in run_cfg.overwrite\n",
    "        ),\n",
    "    )\n",
    "    if nrh:\n",
    "        await process_cache(\n",
    "            run_cfg,\n",
    "            latents_path,\n",
    "            explanations_path,\n",
    "            scores_path,\n",
    "            nrh,\n",
    "            tokenizer,\n",
    "            latent_range,\n",
    "        )\n",
    "\n",
    "    if run_cfg.verbose:\n",
    "        log_results(scores_path, visualize_path, run_cfg.hookpoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_cfg = CacheConfig(\n",
    "    dataset_repo=\"EleutherAI/fineweb-edu-dedup-10b\",\n",
    "    dataset_split=\"train[:50000]\",\n",
    "    dataset_column=\"text\",\n",
    "    batch_size=8,\n",
    "    cache_ctx_len=256,\n",
    "    n_splits=5,\n",
    "    n_tokens=5_000_000,\n",
    ")\n",
    "sampler_cfg = SamplerConfig(\n",
    "    train_type=\"quantiles\",\n",
    "    test_type=\"quantiles\",\n",
    "    n_examples_train=30,\n",
    "    n_examples_test=20,\n",
    "    n_quantiles=10,\n",
    ")\n",
    "constructor_cfg = ConstructorConfig(\n",
    "    min_examples=50,\n",
    "    example_ctx_len=32,\n",
    "    n_non_activating=20,\n",
    "    non_activating_source=\"random\",\n",
    "    faiss_embedding_cache_enabled=True,\n",
    "    faiss_embedding_cache_dir=\".embedding_cache\",\n",
    ")\n",
    "run_cfg = RunConfig(\n",
    "    name=\"fineweb\",\n",
    "    overwrite=[\"cache\", \"scores\"],\n",
    "    model=\"Qwen/Qwen2.5-0.5B\",\n",
    "    sparse_model=\"EleutherAI/sae-pythia-160m-32k\",\n",
    "    hookpoints=[\"layers.17\"],\n",
    "    explainer_model=\"Qwen/Qwen2.5-7B-Instruct\",  # \"meta-llama/Llama-3.2-3B-Instruct\",\n",
    "    # explainer_model_max_len=4096,\n",
    "    # max_latents=5000,\n",
    "    seed=21,\n",
    "    num_gpus=torch.cuda.device_count(),\n",
    "    filter_bos=True,\n",
    "    verbose=True,\n",
    "    sampler_cfg=sampler_cfg,\n",
    "    constructor_cfg=constructor_cfg,\n",
    "    cache_cfg=cache_cfg,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "await run(run_cfg)\n",
    "end_time = time.time()\n",
    "print(f\"Time taken: {end_time - start_time} seconds\")\n",
    "\n",
    "scores_path = Path.cwd() / \"results\" / run_cfg.name / \"scores\"\n",
    "\n",
    "latent_df, _ = load_data(scores_path, run_cfg.hookpoints)\n",
    "processed_df = get_metrics(latent_df)\n",
    "# Performs better than random guessing\n",
    "for score_type, df in processed_df.groupby(\"score_type\"):\n",
    "    accuracy = df[\"accuracy\"].mean()\n",
    "    assert accuracy > 0.55, f\"Score type {score_type} has an accuracy of {accuracy}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_type</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>true_negatives</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>false_negatives</th>\n",
       "      <th>total_examples</th>\n",
       "      <th>total_positives</th>\n",
       "      <th>total_negatives</th>\n",
       "      <th>failed_count</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>true_positive_rate</th>\n",
       "      <th>true_negative_rate</th>\n",
       "      <th>false_positive_rate</th>\n",
       "      <th>false_negative_rate</th>\n",
       "      <th>positive_class_ratio</th>\n",
       "      <th>negative_class_ratio</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>detection</td>\n",
       "      <td>47616</td>\n",
       "      <td>76029</td>\n",
       "      <td>23788</td>\n",
       "      <td>52507</td>\n",
       "      <td>199940</td>\n",
       "      <td>100123</td>\n",
       "      <td>99817</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666853</td>\n",
       "      <td>0.475575</td>\n",
       "      <td>0.555201</td>\n",
       "      <td>0.618629</td>\n",
       "      <td>0.475575</td>\n",
       "      <td>0.761684</td>\n",
       "      <td>0.238316</td>\n",
       "      <td>0.524425</td>\n",
       "      <td>0.500765</td>\n",
       "      <td>0.499235</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score_type  true_positives  true_negatives  false_positives  \\\n",
       "0  detection           47616           76029            23788   \n",
       "\n",
       "   false_negatives  total_examples  total_positives  total_negatives  \\\n",
       "0            52507          199940           100123            99817   \n",
       "\n",
       "   failed_count  precision    recall  f1_score  accuracy  true_positive_rate  \\\n",
       "0             0   0.666853  0.475575  0.555201  0.618629            0.475575   \n",
       "\n",
       "   true_negative_rate  false_positive_rate  false_negative_rate  \\\n",
       "0            0.761684             0.238316             0.524425   \n",
       "\n",
       "   positive_class_ratio  negative_class_ratio   auc  \n",
       "0              0.500765              0.499235  None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df.to_csv(\"results/fineweb/perf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = latent_df.copy().dropna(subset=[\"activating\", \"prediction\"])\n",
    "df.activating = df.activating.astype(int)\n",
    "df.prediction = df.prediction.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_968284/3442901834.py:24: DeprecationWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "def prf(group):\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"precision\": precision_score(\n",
    "                group[\"activating\"],\n",
    "                group[\"prediction\"],\n",
    "                zero_division=0,  # or 1, depending on how you want to handle all-zero cases\n",
    "            ),\n",
    "            \"recall\": recall_score(\n",
    "                group[\"activating\"], group[\"prediction\"], zero_division=0\n",
    "            ),\n",
    "            \"f1\": f1_score(group[\"activating\"], group[\"prediction\"], zero_division=0),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "metrics_by_pk = (\n",
    "    df[[\"activating\", \"prediction\", \"latent_idx\"]]\n",
    "    .dropna(subset=[\"activating\", \"prediction\"], axis=0)\n",
    "    .groupby(\"latent_idx\")\n",
    "    .apply(prf)\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latent_idx</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4657</th>\n",
       "      <td>30411</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3549</th>\n",
       "      <td>23055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>8033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>15183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>23931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>6717</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1581</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>27368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.974359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>11422</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.975610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>19168</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.975610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5017 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      latent_idx  precision  recall        f1\n",
       "4657       30411   0.000000    0.00  0.000000\n",
       "3549       23055   0.000000    0.00  0.000000\n",
       "1238        8033   0.000000    0.00  0.000000\n",
       "2369       15183   0.000000    0.00  0.000000\n",
       "3686       23931   0.000000    0.00  0.000000\n",
       "...          ...        ...     ...       ...\n",
       "1026        6717   0.950000    0.95  0.950000\n",
       "222         1581   0.950000    0.95  0.950000\n",
       "4206       27368   1.000000    0.95  0.974359\n",
       "1773       11422   0.952381    1.00  0.975610\n",
       "2957       19168   0.952381    1.00  0.975610\n",
       "\n",
       "[5017 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_by_pk.sort_values(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
